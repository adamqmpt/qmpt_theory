<!-- file: lab/qmpt_layer_anomaly_simulation_ru.md -->

# Каркас симуляции аномалий слоя QMPT (v0.2)

*Минимальный, но расширяемый математический и симуляционный каркас для проверки QMPT на исторических данных.*

---

## 1. Цель

Задача этого документа:

1. Оформить **минимальное ядро** модели QMPT в форме, удобной для симуляций.
2. Ввести дополнительные переменные, помимо времени и интенсивности:
   - сложность слоя,
   - домены аномалий,
   - связность, знак, наблюдаемость,
   - лаг признания и обратную связь.
3. Описать, как сравнивать:
   - **QMPT-модель** (аномалии зависят от состояния слоя),
   - и **нулевую модель** (случайные «гении»).
4. Задать **метрики и тесты**, пригодные как для игрушечных симуляций, так и для реальных данных.

Документ ориентирован на практику: отсюда должно быть просто перейти к коду (Python / R и т.д.).

---

## 2. Базовые гипотезы

Сравниваются две гипотезы:

- **H_QMPT (структурированная)**  
  Реальность описывается как **слой** со временем изменяющейся сложностью \( C(t) \).  
  Редкие **аномальные узоры** (люди с влиянием на слой) появляются с интенсивностью, зависящей от состояния слоя и инфраструктуры.  
  Эти аномалии:
  - кластеризуются во времени,
  - принадлежат разным **доменам** в разные эпохи,
  - всё быстрее признаются по мере роста сложности.

- **H_0 (нулевая / случайные гении)**  
  Влиятельные фигуры появляются как **однородный или слабо неоднородный пуассоновский процесс**, слабо связанный с \( C(t) \).  
  Кластеры объясняются шумом, эффектами отбора и нарративными искажениями.

Цель симуляции не «доказать» H_QMPT, а проверить:

> Насколько лучше H_QMPT объясняет **наблюдаемые паттерны** (кластеры, смену доменов, лаги), чем H_0?

---

## 3. Переменные и функции

Время дискретно по годам: \( t \in [t_\min, t_\max] \) (например, 1600–2100).

### 3.1. Сложность слоя \( C(t) \)

Гладкая функция в \([0,1]\), описывающая **общую сложность слоя**:

- учитывает:
  - научно-техническое знание,
  - скорость коммуникаций,
  - вычислительные мощности,
  - плотность институтов.

Пример (логистическая функция, параметры подбираются по данным):

\[
C(t) = \frac{1}{1 + \exp(-(t - t_c)/\tau)}
\]

где:

- \( t_c \) – точка перегиба (например, около 1850–1900),
- \( \tau \) – масштаб перехода.

### 3.2. Популяция и рождаемость \( B(t) \)

Приблизительное число рождений в год, масштабированное:

- нужно, чтобы нормировать интенсивность аномалий **на число рождений**, а не только на год.
- достаточно грубой демографической кривой (до 1800 низко, далее рост).

### 3.3. Уровень инфраструктуры / связности \( I(t) \)

Скаляр в \([0,1]\), отражающий, **насколько легко идеям распространяться**:

- прокси: грамотность, коммуникационные технологии, урбанизация.
- обычно растёт позже и быстрее, чем просто население.

Частично коррелирует с \( C(t) \), но не совпадает с ним.

### 3.4. Домены \( D \)

Каждая аномалия принадлежит ровно одному домену \( d \in D \):

- `phys` – физический мир (механика, поля, относительность и т.п.),
- `life` – жизнь, эволюция, биологические структуры,
- `comp` – вычисления, формальные системы, алгоритмы,
- `info` – информация и теория связи,
- `sys` – системы, кибернетика, теория сложности,
- `ont` – онтология реальности, слои, симуляции, сознание.

Для каждого времени \( t \) задаются **веса доменов**:

\[
w_d(t) \ge 0,\quad \sum_{d \in D} w_d(t) = 1
\]

Эти веса кодируют, какой домен «активен» при данной сложности:  
`phys` – при низкой \( C \), `comp` / `info` – при средней, `ont` – при высокой.

### 3.5. Интенсивность аномалий \( \lambda(t) \)

**Суммарная интенсивность** аномалий во времени:

\[
\lambda_{\text{QMPT}}(t) = \lambda_0 \cdot f(C(t), I(t), B(t))
\]

Простейший вариант:

\[
\lambda_{\text{QMPT}}(t) = \lambda_0 \cdot (1 + \alpha_C C(t) + \alpha_I I(t))
\]

Нулевая модель:

\[
\lambda_0(t) = \text{const}
\]

или слабый тренд, не связанный явно с \( C(t) \).

По доменам:

\[
\lambda_d(t) = \lambda_{\text{QMPT}}(t) \cdot w_d(t)
\]

### 3.6. Связность аномалии \( R \)

Для каждой аномалии \( i \), рождённой в момент \( t_i \), определим:

- \( R_i \in [0,1] \): **связность** (насколько узор встроен в инфраструктуру):
  - институты,
  - доступ к инструментам и коллегам,
  - позже – доступ к вычислительным ресурсам и ИИ.

Моделируем:

\[
R_i \sim \text{Beta}(\alpha_R(C(t_i), I(t_i)), \beta_R(C(t_i), I(t_i)))
\]

Высокие \( C \) и \( I \) смещают распределение к \( R \to 1 \).

### 3.7. Наблюдаемость

Не каждая аномалия попадает в исторический нарратив. Введём:

\[
\Pr(\text{наблюдаема } | R_i) = g(R_i)
\]

где \( g(R) \) – возрастающая функция, например:

\[
g(R) = R^\gamma,\quad \gamma \ge 1
\]

События с низким \( R \) становятся **латентными аномалиями**: существуют, но в данных их нет.

### 3.8. Знак аномалии

Каждой аномалии приписывается знак \( s_i \in \{-1, 0, +1\} \):

- \(+1\): увеличивает свободу/понимание/прозрачность слоя,
- \(-1\): усиливает контроль/манипуляцию/угнетение,
- \(0\): нейтральна или неоднозначна.

Определим:

\[
\Pr(s_i = +1 \mid C(t_i)) = p_+(C(t_i)),\quad
\Pr(s_i = -1 \mid C(t_i)) = p_-(C(t_i)),
\]

при этом \( p_+ + p_- + p_0 = 1 \).

Базовая гипотеза: \( p_+(C) \) растёт с \( C \), так как в очень сложном слое тотальный непрозрачный контроль труднее поддерживать.

### 3.9. Лаг признания \( L \)

Для каждой аномалии:

- время рождения \( t_i \),
- время признания \( t_i^{(rec)} = t_i + L_i \),

где \( L_i \ge 0 \) берётся из распределения, среднее которого **уменьшается с ростом сложности**:

\[
\mathbb{E}[L_i \mid C(t_i), I(t_i), R_i] = L_0 - \beta_C C(t_i) - \beta_I I(t_i) - \beta_R R_i,
\]

а сам лаг:

\[
L_i \sim \text{Exponential}(\mu_i), \quad \mu_i = \mathbb{E}[L_i].
\]

### 3.10. Обратная связь на слой

Опционально аномалии могут **изменять** \( C(t) \):

\[
C(t + \Delta t) = C(t) + \sum_{i: t_i^{(rec)} \in [t, t+\Delta t)} \Delta C_i
\]

где \(\Delta C_i\) – вклад аномалии, зависящий от домена и знака.

На первых этапах можно симулировать без обратной связи, затем постепенно её добавлять.

---

## 4. Конвейер симуляции (игрушечный уровень)

### 4.1. Настройка

1. Задать диапазон времени \([t_\min, t_\max]\).
2. Определить функции:
   - \(C(t)\), \(I(t)\), \(B(t)\),
   - веса доменов \( w_d(t) \),
   - параметры интенсивности \( \lambda_0, \alpha_C, \alpha_I \),
   - параметры лагов \( L_0, \beta_C, \beta_I, \beta_R \),
   - функции вероятностей знаков \( p_+(C), p_-(C) \),
   - функцию наблюдаемости \( g(R) \).

3. Выбрать:
   - учитывать ли обратную связь на \( C(t) \),
   - моделировать ли рождаемость явно или оперировать скоростью аномалий по годам.

### 4.2. Генерация аномалий

Для каждого года \( t \):

1. Вычислить интенсивность \( \lambda(t) \) (QMPT или нулевая).
2. Сгенерировать число аномалий:
   \[
   N_t \sim \text{Poisson}(\lambda(t))
   \]
3. Для каждой из \(N_t\) аномалий:
   - выбрать точное время рождения \( t_i = t + u \), \( u \sim U(0,1) \),
   - вычислить \( C(t_i), I(t_i) \),
   - выбрать домен по распределению \( w_d(t_i) \),
   - сэмплировать связность \( R_i \) (Beta),
   - выбрать знак \( s_i \),
   - вычислить ожидаемый лаг и сэмплировать \( L_i \),
   - получить время признания \( t_i^{(rec)} \),
   - отметить, наблюдаема ли аномалия (по \( g(R_i) \)).

### 4.3. Агрегация и метрики

Имея набор событий \( \{ t_i, d_i, s_i, R_i, L_i \} \), можно считать:

- числа аномалий по 50-летним интервалам:
  - всего,
  - по доменам,
  - по знакам,
  - отдельно наблюдаемые и латентные;
- распределения лагов \( L \) в зависимости от:
  - времени рождения,
  - \( C(t) \),
  - \( R \);
- меры «неравномерности» по времени:
  - коэффициент Джини по интервалам,
  - сверхдисперсия относительно однородного пуассона.

---

## 5. Ключевые паттерны для проверки

### 5.1. Временная кластеризация

Ожидания:

- В **QMPT-модели**:
  - интенсивность аномалий растёт с \( C(t) \),
  - появляются явные кластеры около фазовых переходов (например, 1850–1950).
- В **нулевой модели**:
  - числа событий по интервалам примерно одинаковы.

**Проверки:**

- сравнение коэффициентов Джини для QMPT и нулевой модели;
- критерии согласия (хи-квадрат, LR-тесты) против однородного процесса;
- методы поиска точек смены интенсивности (change-point detection).

### 5.2. Смена доменов

Ожидания:

1. доминирование `phys` при низкой сложности,
2. переход к `comp` / `info` при среднем \( C \),
3. доминирование `ont` при высокой сложности.

**Проверки:**

- для каждого домена оценить, в каком диапазоне \( C \) он максимален;
- проверить, согласуется ли порядок пиков (phys → comp/info → ont) с историей.

### 5.3. Тренды лага признания

Ожидания:

- средний лаг \( \mathbb{E}[L] \) убывает с:
  - временем,
  - \( C(t) \),
  - связностью \( R \).

**Проверки:**

- корреляции и регрессии \( L \) против \( C, I, R \);
- сравнение распределений лагов для ранних и поздних эпох (1700–1800 vs 1900–2000).

### 5.4. Соотношение «светлых» и «тёмных» аномалий

Ожидания:

- доля «позитивных» аномалий растёт с \( C(t) \), но не строго монотонно (войны, кризисы).

**Проверки:**

- при наличии разметки исторических фигур по знаку оценить динамику доли «+» и её связь с прокси сложности.

---

## 6. Переход от игрушечных симуляций к реальным данным

### 6.1. Какой датасет нужен

Чтобы выйти за пределы чистой модели, нужно собрать:

- список (100–500) **фигур с реальным влиянием на слой** в областях:
  - физика, математика, биология,
  - вычисления, информация, системы,
  - онтология реальности, философия сознания и слоёв.
- для каждой фигуры:
  - год рождения,
  - год ключевой работы/прорыва,
  - домен(ы),
  - регион / уровень инфраструктуры (грубая оценка),
  - примерный лаг признания (до широкого влияния),
  - опционально знак (+ / – / 0).

Контрольная группа:

- соизмеримый по размеру список «просто крупных учёных», чьи работы **не** радикально меняли модель слоя.

### 6.2. Калибровка и валидация

1. Использовать данные 1600–1950 для **калибровки**:
   - формы \( C(t), I(t) \),
   - параметров \( \alpha_C, \alpha_I, L_0, \beta_C, \beta_I \),
   - весов доменов.
2. Запустить симуляции для 1950–2025 и сравнить:
   - числа аномалий по интервалам,
   - распределения доменов,
   - лаги признания,
   - показатели кластеризации.
3. Использовать период после 2025 года как **прогностическое окно**:
   - например, предсказать количество и тип онтологических аномалий до 2050 г.

---

## 7. Что критично для дальнейших расчётов

Чтобы симуляции были содержательными, важно:

1. **Чётко определить**, кого считать «аномалией слоя», а кого — просто сильным специалистом.
2. **Прозрачно параметризовать** \( C(t), I(t) \) на реальных индикаторах:
   - количество публикаций, патентов,
   - мощность вычислений,
   - скорость коммуникаций и т.д.
3. Проводить **тесты устойчивости**:
   - сохраняются ли паттерны при изменении формы \( C(t) \) и других функций;
   - может ли более простая H_0-модель объяснить те же данные без тонкой подгонки.
4. Сформулировать **проверяемые предсказания**:
   - о кластерах,
   - смене доменов,
   - динамике лагов и знаков.

Если QMPT-подобная модель стабильно лучше объясняет историю появления аномальных паттернов, чем нулевая гипотеза, она переходит из статуса философского наброска в статус **кандидата на метамодель эволюции слоёв и сознаний**.

---

## 8. Следующие шаги

1. Реализовать описанный каркас в коде (Python / R / Julia).
2. Провести **серии симуляций**:
   - под H_QMPT с разными параметрами,
   - под H_0 и промежуточными базовыми моделями.
3. Опубликовать:
   - код и ноутбуки с симуляциями,
   - постепенно — датасет исторических фигур и рассчитанные метрики.
4. Рефакторить формальное ядро QMPT на основе расхождений между моделью и данными.

Этот документ — **слой спецификации**.  
Следующие слои — реализация, симуляции, эмпирическая проверка и корректировка модели.
